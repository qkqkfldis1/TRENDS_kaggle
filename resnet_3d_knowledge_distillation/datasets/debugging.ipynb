{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold,StratifiedKFold, GroupKFold, KFold\n",
    "import nilearn as nl\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import itertools\n",
    "\n",
    "import monai\n",
    "from monai.transforms import \\\n",
    "    LoadNifti, LoadNiftid, AddChanneld, ScaleIntensityRanged, \\\n",
    "    Rand3DElasticd, RandAffined, \\\n",
    "    Spacingd, Orientationd\n",
    "\n",
    "root = r'/home/youhanlee/project/trends/input/'\n",
    "#root = r'/home/iclab/projects/Trends/input/'\n",
    "\n",
    "#train = pd.read_csv('{}/train_scores.csv'.format(root)).sort_values(by='Id')\n",
    "loadings = pd.read_csv('{}/loading.csv'.format(root))\n",
    "sample = pd.read_csv('{}/sample_submission.csv'.format(root))\n",
    "reveal = pd.read_csv('{}/reveal_ID_site2.csv'.format(root))\n",
    "ICN = pd.read_csv('{}/ICN_numbers.csv'.format(root))\n",
    "fnc = pd.read_csv('{}/fnc.csv'.format(root))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Load and display a subject's spatial map\n",
    "\"\"\"\n",
    "\n",
    "def load_subject(filename, mask_niimg):\n",
    "    \"\"\"\n",
    "    Load a subject saved in .mat format with the version 7.3 flag. Return the subject niimg, using a mask niimg as a template for nifti headers.\n",
    "    Args:\n",
    "        filename    <str>            the .mat filename for the subject data\n",
    "        mask_niimg  niimg object     the mask niimg object used for nifti headers\n",
    "    \"\"\"\n",
    "    subject_data = None\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        subject_data = f['SM_feature'][()]\n",
    "        # print(subject_data.shape)\n",
    "    # It's necessary to reorient the axes, since h5py flips axis order\n",
    "    subject_data = np.moveaxis(subject_data, [0, 1, 2, 3], [3, 2, 1, 0])\n",
    "    # print(subject_data.shape)\n",
    "    return subject_data\n",
    "    # subject_niimg = nl.image.new_img_like(mask_niimg, subject_data, affine=mask_niimg.affine, copy_header=True)\n",
    "    # return subject_niimg\n",
    "\n",
    "def read_data_sample():\n",
    "    # Input data files are available in the \"../input/\" directory.\n",
    "    # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "    mask_filename = r'{}/fMRI_mask.nii'.format(root)\n",
    "    subject_filename = '{}/fMRI_train/10004.mat'.format(root)\n",
    "\n",
    "    mask_niimg = nl.image.load_img(mask_filename)\n",
    "    print(\"mask shape is %s\" % (str(mask_niimg.shape)))\n",
    "\n",
    "    subject_niimg = load_subject(subject_filename, mask_niimg)\n",
    "    print(\"Image shape is %s\" % (str(subject_niimg.shape)))\n",
    "    num_components = subject_niimg.shape[-1]\n",
    "    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n",
    "\n",
    "class TReNDsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, mode='train', fold_index = 0, feat_index=0):\n",
    "        # print(\"Processing {} datas\".format(len(self.img_list)))\n",
    "        self.mode = mode\n",
    "        self.fold_index = fold_index\n",
    "        self.feat_index = feat_index\n",
    "        fnc = pd.read_csv('{}/fnc.csv'.format(root))\n",
    "        fnc_columns = fnc.columns[1:]\n",
    "        fnc[fnc_columns] /= 500\n",
    "        \n",
    "        degree = pd.read_csv('{}/degree.csv'.format(root))\n",
    "        degree_columns = degree.columns[:-1]\n",
    "        degree[degree_columns] /= 10000\n",
    "        \n",
    "        train = pd.read_csv('{}/train_scores.csv'.format(root)).sort_values(by='Id')\n",
    "        \n",
    "        if self.mode=='train' or self.mode=='valid' or self.mode=='valid_tta':\n",
    "            features = ('age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2')\n",
    "            good_feats = [f'IC_{feat}' for feat in ['15', '22', '06', '21', '04', '11', '10', '16']]\n",
    "            train = train[['Id', features[self.feat_index]]]\n",
    "            print(train.columns)\n",
    "            \n",
    "            data = pd.merge(loadings, train, on='Id').dropna()\n",
    "            comb = itertools.combinations(good_feats, 2)\n",
    "            for col1, col2 in comb:\n",
    "                data[f'{col1}_x_{col2}'] = data[col1] * data[col2]\n",
    "                data[f'{col1}_+_{col2}'] = data[col1] + data[col2]\n",
    "            \n",
    "            id_train = list(data.Id)\n",
    "            fea_train = np.asarray(data.drop([features[self.feat_index]], axis=1).drop('Id', axis=1))\n",
    "            lbl_train = np.asarray(data[[features[self.feat_index]]])\n",
    "            \n",
    "            # fnc\n",
    "            data = pd.merge(fnc, train, on='Id').dropna()\n",
    "            fnc_train = np.asarray(data.drop([features[self.feat_index]], axis=1).drop('Id', axis=1))\n",
    "            \n",
    "            # degree\n",
    "            data = pd.merge(degree, train, on='Id').dropna()\n",
    "            deg_train = np.asarray(data.drop([features[self.feat_index]], axis=1).drop('Id', axis=1))\n",
    "\n",
    "            self.all_samples = []\n",
    "            for i in tqdm(range(len(id_train))):\n",
    "                id = id_train[i]\n",
    "                fea = fea_train[i]\n",
    "                fnc = fnc_train[i]\n",
    "                deg = deg_train[i]\n",
    "                lbl = lbl_train[i]\n",
    "                filename = os.path.join('{}/fMRI_train_npy/{}.npy'.format(root, id))\n",
    "                self.all_samples.append([filename, fea, fnc, deg, lbl, str(id)])\n",
    "                \n",
    "            fold_df = data[[features[self.feat_index]]]\n",
    "            min_value = fold_df[f'{features[self.feat_index]}'].min()\n",
    "            max_value = fold_df[f'{features[self.feat_index]}'].max()\n",
    "            binsplits = np.arange(min_value,max_value,15)\n",
    "            y_categorized = np.digitize(fold_df[f'{features[self.feat_index]}'].values, bins=binsplits)\n",
    "            \n",
    "            fold_df[f'{features[self.feat_index]}_cat'] = y_categorized\n",
    "\n",
    "            train_indexes = []\n",
    "            valid_indexes = []\n",
    "            kf = StratifiedShuffleSplit(n_splits=5,  random_state=42)\n",
    "            for trn_idx, vld_idx in kf.split(fold_df, fold_df[f'{features[self.feat_index]}_cat']):\n",
    "                train_indexes.append(trn_idx)\n",
    "                valid_indexes.append(vld_idx)\n",
    "                \n",
    "            self.train_index = train_indexes[fold_index]\n",
    "            self.valid_index = valid_indexes[fold_index]\n",
    "\n",
    "            if self.mode=='train':\n",
    "                self.train_index = [tmp for tmp in self.train_index if os.path.exists(self.all_samples[tmp][0])]\n",
    "                self.len = len(self.train_index)\n",
    "                print('fold index:',fold_index)\n",
    "                print('train num:', self.len)\n",
    "\n",
    "            elif self.mode=='valid' or self.mode=='valid_tta':\n",
    "                self.valid_index = [tmp for tmp in self.valid_index if os.path.exists(self.all_samples[tmp][0])]\n",
    "                self.len = len(self.valid_index)\n",
    "                print('fold index:',fold_index)\n",
    "                print('valid num:', self.len)\n",
    "\n",
    "        elif  self.mode=='test':\n",
    "            labels_df = pd.read_csv(\"{}/train_scores.csv\".format(root))\n",
    "            labels_df[\"is_train\"] = True\n",
    "\n",
    "            features = ('age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2')\n",
    "            labels_df = labels_df[['Id', 'is_train', features[self.feat_index]]]\n",
    "            print(labels_df.columns)\n",
    "            data = pd.merge(loadings, labels_df, on=\"Id\", how=\"left\")\n",
    "            \n",
    "            good_feats = [f'IC_{feat}' for feat in ['15', '22', '06', '21', '04', '11', '10', '16']]\n",
    "            #data = pd.merge(loadings, train, on='Id').dropna()\n",
    "            comb = itertools.combinations(good_feats, 2)\n",
    "            for col1, col2 in comb:\n",
    "                data[f'{col1}_x_{col2}'] = data[col1] * data[col2]\n",
    "                data[f'{col1}_+_{col2}'] = data[col1] + data[col2]\n",
    "\n",
    "            id_test = list(data[data[\"is_train\"] != True].Id)\n",
    "            fea_test = np.asarray(data.drop([features[self.feat_index]], axis=1).drop('Id', axis=1)[data[\"is_train\"] != True].drop(\"is_train\", axis=1))\n",
    "            lbl_test = np.asarray(data[[features[self.feat_index]]][data[\"is_train\"] != True])\n",
    "            \n",
    "            data = pd.merge(fnc, labels_df, on=\"Id\", how=\"left\")\n",
    "            fnc_test = np.asarray(data.drop([features[self.feat_index]], axis=1).drop('Id', axis=1)[data[\"is_train\"] != True].drop(\"is_train\", axis=1))\n",
    "            \n",
    "            # degree\n",
    "            data = pd.merge(degree, labels_df, on='Id', how='left')\n",
    "            deg_test = np.asarray(data.drop([features[self.feat_index]], axis=1).drop('Id', axis=1)[data[\"is_train\"] != True].drop(\"is_train\", axis=1))\n",
    "            #print(deg_test.shape)\n",
    "\n",
    "            self.all_samples = []\n",
    "            for i in range(len(id_test)):\n",
    "                id = id_test[i]\n",
    "                fea = fea_test[i]\n",
    "                fnc = fnc_test[i]\n",
    "                deg = deg_test[i]\n",
    "                lbl = lbl_test[i]\n",
    "\n",
    "                filename = os.path.join('{}/fMRI_test_npy/{}.npy'.format(root, id))\n",
    "                if os.path.exists(filename):\n",
    "                    self.all_samples.append([id, filename, fea, fnc, deg, lbl])\n",
    "                    #all_samples.append([filename, fea, fnc, lbl, str(id)])\n",
    "\n",
    "            self.len = len(self.all_samples)\n",
    "            print(len(id_test))\n",
    "            print('test num:', self.len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.mode == \"train\" :\n",
    "            filename, feat, fnc, deg, lbl, id =  self.all_samples[self.train_index[idx]]\n",
    "            train_img = np.load(filename).astype(np.float32)\n",
    "            train_img = train_img.transpose((3,2,1,0))\n",
    "            # (53, 52, 63, 53)\n",
    "            train_lbl = lbl\n",
    "\n",
    "            data_dict = {'image': train_img}\n",
    "            rand_affine = RandAffined(keys=['image'],\n",
    "                                      mode=('bilinear', 'nearest'),\n",
    "                                      prob=0.5,\n",
    "                                      spatial_size=(52, 63, 53),\n",
    "                                      translate_range=(5, 5, 5),\n",
    "                                      rotate_range=(np.pi * 4, np.pi * 4, np.pi * 4),\n",
    "                                      scale_range=(0.15, 0.15, 0.15),\n",
    "                                      padding_mode='border')\n",
    "            affined_data_dict = rand_affine(data_dict)\n",
    "            train_img = affined_data_dict['image']\n",
    "            train_feat = feat #affined_data_dict['feat']\n",
    "            train_fnc = fnc#affined_data_dict['fnc']\n",
    "            train_deg = deg#affined_data_dict['deg']\n",
    "\n",
    "            return torch.FloatTensor(train_img), \\\n",
    "                   torch.FloatTensor(train_feat), \\\n",
    "                   torch.FloatTensor(train_fnc), \\\n",
    "                   torch.FloatTensor(train_deg), \\\n",
    "                   torch.FloatTensor(train_lbl)\n",
    "\n",
    "        elif self.mode == \"valid\":\n",
    "            filename, feat, fnc, deg, lbl, id =  self.all_samples[self.valid_index[idx]]\n",
    "            train_img = np.load(filename).astype(np.float32)\n",
    "            train_img = train_img.transpose((3, 2, 1, 0))\n",
    "            # (53, 52, 63, 53)\n",
    "            train_lbl = lbl\n",
    "\n",
    "            return torch.FloatTensor(train_img), \\\n",
    "                   torch.FloatTensor(feat), \\\n",
    "                   torch.FloatTensor(fnc), \\\n",
    "                   torch.FloatTensor(deg), \\\n",
    "                   torch.FloatTensor(train_lbl)\n",
    "\n",
    "\n",
    "        elif self.mode == 'test':\n",
    "            id, filename, feat, fnc, deg, lbl =  self.all_samples[idx]\n",
    "            test_img = np.load(filename).astype(np.float32)\n",
    "            test_img = test_img.transpose((3, 2, 1, 0))\n",
    "            \n",
    "            return str(id), \\\n",
    "                   torch.FloatTensor(test_img), \\\n",
    "                   torch.FloatTensor(feat), \\\n",
    "                   torch.FloatTensor(fnc), \\\n",
    "                   torch.FloatTensor(deg)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'domain2_var2'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5838/5838 [00:00<00:00, 423741.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold index: 0\n",
      "valid num: 584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/youhanlee/anaconda3/envs/lyh/lib/python3.7/site-packages/ipykernel_launcher.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dataset = TReNDsDataset(mode='valid', fold_index=0, feat_index=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53, 52, 63, 53])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([82])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1378])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([39.6290])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.rand(16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.rand(16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0594)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nae(inp, targ):\n",
    "    return torch.mean(torch.abs(inp - targ)) / torch.mean(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5592)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(outputs - labels)) / torch.mean(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5456)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(outputs.squeeze() - labels)) / torch.mean(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5843)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(outputs - labels) / torch.mean(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4094e-02, 3.7942e-01, 8.1290e-01, 2.9592e-01, 8.0429e-01, 2.2818e-01,\n",
       "         8.0552e-01, 1.7403e-01, 1.4870e-01, 3.4781e-01, 1.3194e-01, 2.1497e-01,\n",
       "         3.4613e-01, 4.9025e-01, 1.0067e-01, 4.5689e-01],\n",
       "        [3.4789e-01, 1.7436e-02, 4.5092e-01, 6.6056e-02, 4.4231e-01, 1.3380e-01,\n",
       "         4.4354e-01, 1.8795e-01, 5.1068e-01, 1.4167e-02, 2.3004e-01, 1.4701e-01,\n",
       "         1.5849e-02, 1.2827e-01, 4.6265e-01, 9.4910e-02],\n",
       "        [2.4063e-01, 1.2469e-01, 5.5818e-01, 4.1202e-02, 5.4957e-01, 2.6541e-02,\n",
       "         5.5080e-01, 8.0693e-02, 4.0342e-01, 9.3091e-02, 1.2278e-01, 3.9747e-02,\n",
       "         9.1410e-02, 2.3553e-01, 3.5540e-01, 2.0217e-01],\n",
       "        [4.8157e-01, 1.1625e-01, 3.1723e-01, 1.9974e-01, 3.0863e-01, 2.6749e-01,\n",
       "         3.0985e-01, 3.2164e-01, 6.4437e-01, 1.4785e-01, 3.6373e-01, 2.8069e-01,\n",
       "         1.4953e-01, 5.4163e-03, 5.9634e-01, 3.8776e-02],\n",
       "        [7.4709e-02, 2.9061e-01, 7.2409e-01, 2.0712e-01, 7.1549e-01, 1.3938e-01,\n",
       "         7.1671e-01, 8.5224e-02, 2.3751e-01, 2.5901e-01, 4.3135e-02, 1.2617e-01,\n",
       "         2.5733e-01, 4.0145e-01, 1.8948e-01, 3.6809e-01],\n",
       "        [6.4016e-01, 2.7483e-01, 1.5865e-01, 3.5833e-01, 1.5004e-01, 4.2607e-01,\n",
       "         1.5127e-01, 4.8022e-01, 8.0295e-01, 3.0644e-01, 5.2231e-01, 4.3928e-01,\n",
       "         3.0812e-01, 1.6400e-01, 7.5492e-01, 1.9736e-01],\n",
       "        [7.9853e-01, 4.3321e-01, 2.7376e-04, 5.1670e-01, 8.3293e-03, 5.8444e-01,\n",
       "         7.1067e-03, 6.3860e-01, 9.6133e-01, 4.6481e-01, 6.8068e-01, 5.9765e-01,\n",
       "         4.6649e-01, 3.2237e-01, 9.1330e-01, 3.5573e-01],\n",
       "        [1.3391e-01, 2.3141e-01, 6.6489e-01, 1.4792e-01, 6.5629e-01, 8.0174e-02,\n",
       "         6.5751e-01, 2.6022e-02, 2.9671e-01, 1.9981e-01, 1.6067e-02, 6.6968e-02,\n",
       "         1.9812e-01, 3.4224e-01, 2.4868e-01, 3.0888e-01],\n",
       "        [4.0692e-01, 4.1595e-02, 3.9189e-01, 1.2509e-01, 3.8328e-01, 1.9283e-01,\n",
       "         3.8451e-01, 2.4698e-01, 5.6971e-01, 7.3197e-02, 2.8907e-01, 2.0604e-01,\n",
       "         7.4879e-02, 6.9239e-02, 5.2168e-01, 3.5879e-02],\n",
       "        [4.4166e-01, 7.6343e-02, 3.5714e-01, 1.5983e-01, 3.4854e-01, 2.2758e-01,\n",
       "         3.4976e-01, 2.8173e-01, 6.0446e-01, 1.0795e-01, 3.2382e-01, 2.4078e-01,\n",
       "         1.0963e-01, 3.4491e-02, 5.5643e-01, 1.1313e-03],\n",
       "        [1.6159e-01, 2.0373e-01, 6.3722e-01, 1.2024e-01, 6.2861e-01, 5.2499e-02,\n",
       "         6.2984e-01, 1.6536e-03, 3.2438e-01, 1.7213e-01, 4.3743e-02, 3.9293e-02,\n",
       "         1.7045e-01, 3.1457e-01, 2.7636e-01, 2.8121e-01],\n",
       "        [3.5731e-02, 3.2959e-01, 7.6307e-01, 2.4610e-01, 7.5447e-01, 1.7836e-01,\n",
       "         7.5569e-01, 1.2420e-01, 1.9853e-01, 2.9799e-01, 8.2114e-02, 1.6515e-01,\n",
       "         2.9631e-01, 4.4042e-01, 1.5050e-01, 4.0706e-01],\n",
       "        [3.1309e-01, 5.2233e-02, 4.8572e-01, 3.1259e-02, 4.7711e-01, 9.9002e-02,\n",
       "         4.7834e-01, 1.5315e-01, 4.7588e-01, 2.0631e-02, 1.9524e-01, 1.1221e-01,\n",
       "         1.8949e-02, 1.6307e-01, 4.2786e-01, 1.2971e-01],\n",
       "        [7.0692e-01, 3.4160e-01, 9.1886e-02, 4.2509e-01, 8.3283e-02, 4.9283e-01,\n",
       "         8.4505e-02, 5.4698e-01, 8.6971e-01, 3.7320e-01, 5.8907e-01, 5.0604e-01,\n",
       "         3.7488e-01, 2.3076e-01, 8.2169e-01, 2.6412e-01],\n",
       "        [5.9944e-01, 2.3412e-01, 1.9936e-01, 3.1761e-01, 1.9076e-01, 3.8535e-01,\n",
       "         1.9198e-01, 4.3951e-01, 7.6224e-01, 2.6572e-01, 4.8159e-01, 3.9856e-01,\n",
       "         2.6740e-01, 1.2328e-01, 7.1421e-01, 1.5664e-01],\n",
       "        [6.6577e-01, 3.0045e-01, 1.3303e-01, 3.8394e-01, 1.2443e-01, 4.5169e-01,\n",
       "         1.2565e-01, 5.0584e-01, 8.2857e-01, 3.3205e-01, 5.4793e-01, 4.6489e-01,\n",
       "         3.3373e-01, 1.8962e-01, 7.8054e-01, 2.2298e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(outputs - labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3837)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(outputs - labels) / labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyh",
   "language": "python",
   "name": "lyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
